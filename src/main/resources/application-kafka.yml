spring:
  kafka: #kafka中，需要配置kafka的启动配置文件中的：advertised.listeners=PLAINTEXT://localhost:9092，然后才能配置broker地址
#    消费者配置
    consumer:
      client-id: Springboot-consumer  #指定id
      enable-auto-commit: true #开启自动提交
      auto-commit-interval: 5s  #自动提交的时间间隔（默认为5秒）
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer #指定消费者接收到的value的反序列化器
      auto-offset-reset: latest #当消费者发现偏移量无效或者seek方法找不到下标时，选择从最早的数据开始读（earliest）或者只读最新的数据(latest)，或者直接抛出以异常(none)
      fetch-min-size: 1B  #（原始配置:fetch-min-bytes）指定消费者每次可获得的最小字节数，默认1字节（增大此配置提交吞吐量，会增大延迟）
      fetch-max-wait: 1000ms #指定从broker获取数据的等待时间，默认为500ms,和fetch-min-size配合使用（调小此值可以减小延迟）
      max-poll-records: 500  #pall方法能够返回的最大记录数量，默认为500条（如果消息的大小都比较小，则可以增大该值提升消费速度）
      heartbeat-interval: 1000ms #消费者心跳发送的间隔，必须小于heartbeat-interval的配置，一般为session.timeout.ms的1/3左右
      properties:
        max.poll.interval.ms: 30000 #每俩次poll拉取数据时间间隔最大超时时间，超过这个值，broker就会认为你这个消费者挂了，并且重新平衡，这时候就消费不到信息了（默认三百秒）
        fetch.max.bytes: 52428800 #poll方法最大能拉取的数据量，默认50MB，
        spring.json.trusted.packages: "*" #将需要序列化的类所属的包添加到kafka信任的包路径下，否则Kafka反序列化会失败的！！！！！！！！！！
        max.partition.fetch.bytes: 1048576‬  #服务器从每个分区返回给消费者的最大字节数，默认1MB
        connextions.max.idle.ms: 540000 #指定多久之后关闭限制的连接，默认9分钟
        exclude.internal.topics: true #__consumer_offsets和__transaction_status主题是否可以向消费者公开，如果为true，则只能通过subscribe(Collection)方法订阅，不能用subscribe(Collection)方法订阅，为false则没有这个限制
        receive.buffer.bytes: 65536 #指定TCP接收数据缓冲区大小，为-1使用系统默认值（默认64KB）
        send.buffer.bytes: 131072 #指定TCP发送数据缓冲区大小，为-1使用系统默认值（默认128KB）
        request.timeout.ms: 30000 #Consumer等待响应的最长时间，默认为30s
        matadata.max.age.ms: 300000 #元数据如果在这个时间内未更新，则会强制更新（默认为300000ms:5分钟）
        reconnect.backoff.ms: 50 #配置尝试重新连接指定主机之前的等待时间避免频繁地连接主机（默认为50ms）
        retry.backoff.ms: 100 #指定重新发送失败的请求到指定的主题分区之前等待时间（默认100ms）
        isolation.level: read_uncommitted #消费者事务隔离级别（默认为：read_uncommitted）
        partition.assignment.strategy: org.apache.kafka.clients.consumer.RangeAssignor,org.apache.kafka.clients.consumer.RoundRobinAssignor,org.apache.kafka.clients.consumer.StickyAssignor # 指定分区策略类
        session.timout.ms: 3000ms  # 超时时间，如果超过此时间没有收到心跳，则认为消费者已经挂了。（默认10秒），改配置值必须在broker的group.min.session.timeout.ms（默认6000）和group.max.session.timeout.ms（默认300000）的范围内
    #生产者配置
    producer:
      client-id: springboot-producer #随意配置，用于日志
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer #指定生产者发送的value的序列化器
      acks: 1 #0,all    为1：只要分区的首领收到就算发送成功、为0：不管收没收到都算成功，为all（或者-1）：必须所有参与复制的节点都收到才算发送成功（默认为1）
      buffer-memory: 33554432 #发送者的缓冲区大小（默认为33554432B:32MB）
      compression-type: snappy #gzip,lz4   设置压缩的算法，snappy算法cpu占用少，压缩比小，gzip算法cpu占用多，压缩比大(如果对延迟有一定的要求，则不推荐压缩)
      retries: 3  #如果大于0，则开启发送失败后的重试,数字为重试的次数
      batch-size: 1048576  #发送同一分区的数据的缓存大小，设大一点不会造成延时，设小了会有额外开销
      properties: #自定义属性
        #partitioner.class: KafkaPartitioner #配置自定义分区器，指定分区器的包路径
        retry.backoff.ms: 200 #每次发送失败之后的等待时间。和retries配合使用
        linger.ms: 0 #发送ProducerBatch数据之前的等待时间；当发送数据时，如果ProducerBatch没满，继续等待更多数据加入ProducerBatch，知道达到linger.ms时间（默认为0）
        max.in.flight.requests.per.connection: 10 #生产者接收到响应之前可以发送的消息数量，为1可以保证数据接收是按照发送的顺序来的(顺序要求严格，吞吐量较低，默认为5)
        max.block.ms: 600000 #配置了在调用send方法或使用partitionsFor方法能获取元数据时生产者的阻塞时间。（默认600000ms:60s）
        max.request.size: 201400 #生产者一次能发送消息的最大值，最好与broker的配置匹配（默认为1048576B:1MB）
        receive.buffer.bytes: 32768 #指定Socket接收数据缓冲区大小，为-1使用系统默认值（默认为32768B:32KB）
        send.buffer.bytes: 131072 #指定Socket发送数据缓冲区大小，为-1使用系统默认值（默认为131072B:128KB）
        connections.max.idle.ms: 540000 #多长时间之后关闭限制的连接（默认为540000ms:9分钟）
        request.timeout.ms: 30000 #生产者等待请求响应的最长时间（默认为30000ms:即30秒）
        matadata.max.age.ms: 300000 #元数据如果在这个时间内未更新，则会强制更新（默认为300000ms:5分钟）
        enable.idempotence: true #是否开启幂等性，需要其他配置配合：（retries必须大于0、acks必须为-1、max.in.flight.requests.per.connection必须不大于5）
    #broker地址列表，不需要包含所有的broker地址，生产者会从给定的 broker查找到其他broker的信息。
    bootstrap-servers: 101.37.172.37:9091,101.37.172.37:9092 #不必要全部列举出来，但建议至少要提供两个broker的信息，一且其中一个宕机，生产者仍然能够连接到集群上。
    template:
      default-topic: test #template默认的topic
    listener:
      concurrency: 6

    # Broker端的配置
    broker:
      properties:
        offsets.topic.replication.factor: 1 # 副本因子个数
        offsets.topic.num.partitions: 3 #分区个数
        offsets.retention.minutes: 1400 #已保存的下标保存的分钟数，超过此时间，则下标会丢失默认为1天（默认为1440，即一天）
        offset.metadata.max.bytes: 4096 #手动提交下标时，元数据的最大长度（默认为4096）